{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quicksort\n",
    "\n",
    "**Quicksort** is a recursive method:\n",
    "\n",
    "- Shuffles the array\n",
    "- Creates a partition so there is a `j` where entry `a[j]` is in place, there's no larger entry to the left of `j`, and no smaller entry to the right of `j`\n",
    "- Recursively sort the left part and right part\n",
    "\n",
    "Phase I (repeat until `i` and `j` cross:\n",
    "- Choose the first element as `a[lo]`\n",
    "- Scan `i` from left to right as long as `a[i] < a[lo]`\n",
    "- Scan `j` from right to left so long as `a[j] > a[lo]`\n",
    "- Exchange `a[i]` with `a[j]`\n",
    "\n",
    "Phase II is to take each half around the partition and run phase I on it (using the first item as the new partition).\n",
    "\n",
    "Typically partition in place - you can use an extra array to make it easier (and stable), but it's usually no worth the cost. One of the advantages of it over mergesort is that it's in place.\n",
    "\n",
    "Two tricky parts are keeping the indices `i` and `j` from crossing (terminating the loop) and staying in bounds (`j == lo` test is redundant but `i == hi` isn't). The shuffling part is necessary for performance guarantees. Also, when there are duplicate keys, it's better to stop on keys equal to the partitioning item's key.\n",
    "\n",
    "Quicksort is even faster than mergesort.\n",
    "\n",
    "In the best case, quicksort will divide the array in half with each partition, and is then similar to mergesort with $N \\lg N$. The worst case is if the array is already sorted, so each partition just peals off the first item, which is ~$\\frac{1}{2} N^2$. But with random shuffling, that's highly unlikely to happen.\n",
    "\n",
    "The average case (by number of compares) is more interesting.\n",
    "\n",
    "The proposition is the average number of compares $C_N$ to quicksort an array of $N$ distinct keys is ~$2N \\ln N$ (and the number of exchanges is ~$\\frac{1}{3} N \\ln N$).\n",
    "\n",
    "**The proof**: $C_N$ satisfies the recurrence $C_0 = C_1 = 0$ and for $N \\geq 2$. The following shows $C_N$ equal to the partitioning plus each left + right over the partitioning probability:\n",
    "\n",
    "$$\n",
    "C_N = (N + 1) + \\bigg{(} \\frac{C_0 + C_{N-1}}{N} \\bigg{)} + \\bigg{(} \\frac{C_1 + C_{N-2}}{N} \\bigg{)} + \\cdots + \\bigg{(} \\frac{C_{N-1} + C_0}{N} \\bigg{)} \\\\\n",
    "\\text{Multiply both sides by } N \\\\\n",
    "NC_N = N(N + 1) + 2(C_0 + C_1 + \\ldots + C_{N-1}) \\\\\n",
    "\\text{Subtract this from the same equation for } N-1: \\\\\n",
    "NC_N - (N - 1)C_{N-1} = 2N + 2C_{N-1} \\\\\n",
    "\\text{Repeatedly apply the above equation, get approximate sum by integral:} \\\\\n",
    "C_N \\text{~} 2(N + 1) \\ln N \\approx 1.39 N \\lg N\n",
    "$$\n",
    "\n",
    "**Worst case**, the number of compares is quadratic ($N^2$), but that's extremely unlikely with a random shuffle (it's a probabilistic guarantee against the worst case, and important for performance). Many text book implementations go quadratic if the array is already sorted/reverse sorted, or there are many duplicates. There are about 39% more compares than mergesort, but it's faster in practice because of less data movement.\n",
    "\n",
    "**Summary of properties**:\n",
    "\n",
    "- **In place**: partitioning is done with constant extra space\n",
    "- **Depth of recursion**: can guarantee logarithmic depth by recurring on smaller subarrays before larger subarrays, so get logarithmic extra space with high probability\n",
    "- **Not stable**: long-range swaps can pull items out of relative order\n",
    "\n",
    "Practical improvements:\n",
    "\n",
    "- Quicksort has too much overhead for small subarrays, can use insertion sort for arrays with ~10 items, or delay using it until one pass at the end\n",
    "- Estimate the partitioning item instead of using the first item. The best choice for the pivot item is the median, can find a decent estimate by taking 3 random items and taking the median of that (improves performance by ~10%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Quicksort implementa"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
