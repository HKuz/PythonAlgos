{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hash Tables\n",
    "\n",
    "A **hash table** is a data structure that implements symbol tables  with constant-time performance for core operations, provided that search keys are standard data types or simply defined. It uses different access to the data compared to other BSTs, and doesn't support ordered operations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hashing and Hash Functions\n",
    "\n",
    "The basic idea of **hashing** is to save items in a *key-indexed table* where the index is a function of the key. A **hash function** is a method for computing the array index from the given key.\n",
    "\n",
    "Issues:\n",
    "\n",
    "- Computing the hash function\n",
    "- Equality test: method for checking whether two keys are equal\n",
    "- Collision resolution: algorithm and data structure to handle two keys that hash to the same array index\n",
    "\n",
    "Hashing is a classic space-time tradeoff. With no space limitation, you use a trivial hash function with the key as the index. With no time limitation, you hash everything to the same place (use a trivial collision resolution) and do sequential search. In the real world with space and time limitations, you use hashing.\n",
    "\n",
    "**Computing the hash function**\n",
    "\n",
    "The idealistic goal is to scramble the keys uniformly to produce a table index - it's efficiently computable and each table index is equally likely for each key. You have an array the size of $M$ and $N$ keys to insert.\n",
    "\n",
    "There are usually built-in methods in your language of choice for doing this with different data types.\n",
    "\n",
    "**Modular hashing:**\n",
    "\n",
    "- Hash code: an integer between $-2^{31}$ and $2^{31} - 1$\n",
    "- Hash function: you want it to produce an integer between $0$ and $M - 1$ (for use as the array index). $M$ is typically a prime or a power of 2\n",
    "\n",
    "The math that makes this work is to hash the key, get rid of the sign by taking `and` with $2^{31}$ in hexidecimal, then mod with $M$: `(hash(key) & 0x7fffffff) % M`.\n",
    "\n",
    "The **uniform hashing assumption** is that each key is equally likely to hash to an integer between $0$ and $M - 1$. Think of throwing balls at random into $M$ bins. The **birthday problem** (when will you expect your first collision, or when 2 people in a room have the same birthday) is you'd expect two balls in the same bin after ~$\\sqrt{\\pi M / 2}$ tosses. The **coupon collector** assumption is that you expect every bin has $\\geq 1$ ball after ~$M \\ln M$ tosses. And the **load balancing** problem says that after $M$ tosses, you expect that the most loaded bin has $\\Theta (\\log M / \\log \\log M)$ balls."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separate Chaining\n",
    "\n",
    "**Separate chaining** is a collision resolution strategy that makes use of the linked list data structure. A collision happens when two distinct keys hash to the same index.\n",
    "\n",
    "The **birthday problem** said that you need huge amounts of memory (quadratic) to avoid a collision, which is too much in practice. And the **coupon collector** and **load balancing** problems said that collisions will be evenly distributed. \n",
    "\n",
    "So, how do you handle collisions efficiently?\n",
    "\n",
    "Separate chaining is one solution that uses an array of $M \\lt N$ linked lists:\n",
    "\n",
    "- Hash: map kay to integer $i$ between $0$ and $M - 1$\n",
    "- Insert: put at front of $i^{th}$ chain (if not already there)\n",
    "- Search: need to search only $i^{th}$ chain\n",
    "\n",
    "Proposition is that under the uniform hashing assumption, the probability that the number of keys in a list is within a constant factor of $N/M$ is extremely close to $1$. The proof shows that the distribution of the list size obeys a binomial distribution.\n",
    "\n",
    "The consequence is that the number of probes for search/insert is proportional to $N/M$:\n",
    "\n",
    "- $M$ is too large $\\implies$ too many empty chains\n",
    "- $M$ is too small $\\implies$ chains are too long\n",
    "- Typical choice: $M \\text{~} N/5$ for constant-time operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Probing\n",
    "\n",
    "**Linear probing** is another popular collision resolution method. It uses **open addressing**, so when a key collides, it finds the next empty slot and puts the data there. Instead of keeping linked lists in positions along an array, you just allocate an array the size of the data.\n",
    "\n",
    "The idea is to first hash the key to map it to an integer $i$ between $0$ and $M-1$. Then insert the key at index $i$ in the array if that slot if free, if not, try $i+1$, $i+2$, etc. To search, get the hash of the key, check index $i$ in the array, if that slot is occupied but there's no match, try $i+1$, $i+2$, etc. until you find it or hit an empty slot. A group of keys in consecutive slots in the array are called a cluster.\n",
    "\n",
    "The size of the array $M$ *must be* greater than the number of key-value pairs $N$. Implementations usually include array re-sizing code to adjust $M$ for the size of the data.\n",
    "\n",
    "In the earlier days of computing where memory was at a premium, a lot of care went into preventing empty keys or linked lists. One observation was that new keys were likely to hash into the middle of big clusters, and big clusters were likely to get longer.\n",
    "\n",
    "**Knuth's parking problem** frames it as cars parking on a one-way street, if every car starts looking for a place at a random time, how far do they have to go to find a spot? He could show that if half the spots are occupied ($M/2$), on average, half find a spot in one place, half go one more spot (mean displacement of ~$3/2$). But when it's full ($M$ cars), the mean displacement is ~$\\sqrt{\\pi M/8}$.\n",
    "\n",
    "**Proposition:** under uniform hashing assumption, the average number of probes in a linear probing hash table of size $M$ that contains $N = \\alpha M$ keys is:\n",
    "\n",
    "**Search hit:**\n",
    "$$\n",
    "\\text{~} \\frac{1}{2} \\bigg( 1 + \\frac{1}{(1-\\alpha)} \\bigg)\n",
    "$$\n",
    "\n",
    "**Search miss or Insert:**\n",
    "$$\n",
    "\\text{~} \\frac{1}{2} \\bigg( 1 + \\frac{1}{(1-\\alpha)^2} \\bigg)\n",
    "$$\n",
    "\n",
    "**Parameters:**\n",
    "\n",
    "- $M$ too large $\\implies$ too many empty array entries\n",
    "- $M$ too small $\\implies$ search time blows up\n",
    "- Typical choice: $\\alpha = N/M \\text{~} \\frac{1}{2}$ so the number of probes for a hit is ~3/2 and for search miss/insert is ~5/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LinearProbingHashST:\n",
    "    def __init__(self, M):\n",
    "        self.M = M\n",
    "        self.key_arr = [None] * M\n",
    "        self.vals_arr = [None] * M\n",
    "        self.count = 0\n",
    "    \n",
    "    def hash_function(self, key):\n",
    "        return (hash(key) & 0x7fffffff) % self.M\n",
    "\n",
    "    def put(self, key, value):\n",
    "        # Inserts key and value into arrays at hashed or next avail index\n",
    "        i = self.hash_function(key)\n",
    "        while self.key_arr[i] is not None and self.key_arr[i] != key:\n",
    "            # Will be inf loop if array is full and doesn't contain key\n",
    "            i = (i + 1) % self.M\n",
    "        self.key_arr[i] = key\n",
    "        self.vals_arr[i] = value\n",
    "        self.count += 1\n",
    "    \n",
    "    def get(self, key):\n",
    "        i = self.hash_function(key)\n",
    "        while self.key_arr[i] is not None:\n",
    "            # Will be inf loop if array is full and doesn't contain key\n",
    "            if key == self.key_arr[i]:\n",
    "                return self.vals_arr[i]\n",
    "            i = (i + 1) % self.M\n",
    "        return None\n",
    "    \n",
    "    def __contains__(self, key):\n",
    "        return self.get(key) is not None\n",
    "    \n",
    "    def __str__(self):\n",
    "        return str(self.key_arr)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B', 'P', None, 'E', 'S', 'T', 'H', 'A', 'Z', 'Q', None]\n",
      "3, 4, 4, 9, 7, 0, 8, 3, 0, "
     ]
    }
   ],
   "source": [
    "lin_probe = LinearProbingHashST(11)\n",
    "for letter in ['E', 'S', 'T', 'Q', 'A', 'B', 'Z', 'H', 'P']:\n",
    "    lin_probe.put(letter, lin_probe.hash_function(letter))\n",
    "print(lin_probe)\n",
    "for letter in ['E', 'S', 'T', 'Q', 'A', 'B', 'Z', 'H', 'P']:\n",
    "    print(lin_probe.get(letter), end=\", \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hash Table Context\n",
    "\n",
    "Hashing is widely used and appears in a lot of different contexts.\n",
    "\n",
    "In Java, computing the hash function for long strings took time, so an early version (1.1) only examined every 8-9 evenly spaced characters. The benefit was it saved time performing the arithmetic of the hash function. This highlights a consideration with hashing: does the cost of computing the hash function for a complicated key exceed the cost of searching and using a simpler structure (like a binary search tree)? The downside in this example was there was great potential for bad collision patterns in typical data, like urls that are similar.\n",
    "\n",
    "When you need guaranteed performance in real world scenarios (aircraft control or controlling someone's pacemaker), you can't always rely on the uniform hashing assumption holding in practice. In these situations, you may want the performance guarantee of a red-black search tree.\n",
    "\n",
    "Denial of Service (DOS) attacks on the web rely on hash functions saving certain information to the same slot, and take advantage of that.\n",
    "\n",
    "Hashing is extremely important in e-commerce - they use **one-way hash functions**, where it's hard to find a key that will hash to a desired value (or two keys that hash to the same value). Examples include `SHA-2`, `WHIRLPOOL`, and `RIPEMD-160`. They're used as a digital fingerprint, message digest, or for storing passwords. Unfortunately, they're also too expensive to practically use in symbol table implementations.\n",
    "\n",
    "### Separate Chaining vs. Linear Probing\n",
    "\n",
    "**Separate Chaining**\n",
    "- Easier to implement delete functionality\n",
    "- Performance degrades gracefully\n",
    "- Clustering is less sensitive to poorly-designed hash function\n",
    "\n",
    "**Linear Probing**\n",
    "- Less wasted space\n",
    "- Better cache performance (for huge tables)\n",
    "\n",
    "Classic considerations are how to implement delete and how to resize?\n",
    "\n",
    "Some improved variations:\n",
    "\n",
    "**Two-probe Hashing (separate chaining variation)**\n",
    "- Hash to two positions, insert key in shorter of the two chains\n",
    "- Reduces expected length of the longest chain to $\\log \\log N$\n",
    "\n",
    "**Double Hashing (linear-probing variation)**\n",
    "- Use linear probing, but skip colliding slots by a variable amount, not just 1 each time\n",
    "- Effectively eliminates clustering\n",
    "- Can allow table to become nearly full\n",
    "- More difficult to implement delete\n",
    "\n",
    "**Cuckoo Hashing (linear-probing variation)**\n",
    "- Hash key to two positions; insert key into either position; if occupied, reinsert displaced key into its alternative position (and recur)\n",
    "- Constant worst-case time for search\n",
    "\n",
    "### Hash Tables vs. Balanced Search Trees\n",
    "\n",
    "**Hash Tables**\n",
    "- Simpler to code (if you don't have to create the hash function)\n",
    "- No effective alternative for unordered keys (if you don't have order in the keys at all, you have to use hashing because you don't have the necessary `compareTo()` function to use a BST)\n",
    "- Faster for simple keys (a few arithmetic operations versus $\\log N$ compares)\n",
    "- Can have better system support for strings (e.g. in Java, with cached hash code)\n",
    "\n",
    "**Balanced Search Trees**\n",
    "- Stronger performance guarantee\n",
    "- Support for ordered symbol table operations\n",
    "- Easier to implement `compareTo()` function correctly than it is to do `equals()` and `hashCode()`\n",
    "\n",
    "Most systems include both, so programmers can decide which works better for their specific application. Generally, the main reason to use a hash table over a red-black BST is that you get better performance in practice on typical inputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Symbol Table Applications\n",
    "\n",
    "### Sets\n",
    "\n",
    "A mathematical **set** is a collection of distinct keys. The data structure is even simpler than symbol tables because there's no associated value, just keys. The implementation is just to remove any reference to \"value\" in any of the symbol table structures.\n",
    "\n",
    "Another application is an **exception filter**, where you read in a list of words from one file, then print out all the words from standard input that are {in, not in} the given list. Useful in spell checkers (identify misspelled words), in a browser (mark visited pages, block sites), or with credit cards (check for stolen cards).\n",
    "\n",
    "### Dictionary Clients\n",
    "\n",
    "An example of a dictionary client is to create an application that builds a symbol table off a CSV file, which takes three arguments: the file name, an integer for which column/field to use as the key, and an integer for which one to use as the value.\n",
    "\n",
    "For example, a CSV file of website domain names in one column and IP addresses in the other. You'd run the program name \"LookupCSV\" from the command line with: `python LookupCSV ip.csv 0 1`.\n",
    "\n",
    "Since ordered operations (such as rank and ordered iteration) are not needed, a hash table implementation (such as linear probing) is most suitable for this example.\n",
    "\n",
    "### Indexing Clients\n",
    "\n",
    "Another common function easily handled by symbol tables is indexing.\n",
    "\n",
    "For file indexing, the goal is to create an index for a list of specified files so that you can efficiently find all the files that contain a given search query string. Spotlight or Find programs on your computer do this.\n",
    "\n",
    "You can implement with a symbol table where the key is the query string and the value is the set of files containing that string.\n",
    "\n",
    "### Sparse Vectors\n",
    "\n",
    "Sparse vectors in math present another way to apply symbol tables. When there are a lot of zero entries in a matrix (\"sparse\"), the standard dot product implementation (taking the sum product of a matrix row with a vector column) isn't as efficient as it could be.\n",
    "\n",
    "For a vector, the classic representation is a 1D array, where every element is saved in the array. You have constant time access to elements but the space is proportional to $N$.\n",
    "\n",
    "The symbol table representation for a vector (a **sparse vector**) uses the index as the key and the entry as the value for only non-zero entries. It is an efficient iterator and the space used is proportional to the number of non-zero entries. You can use a hash table, because the order in which you process the entries isn't important, you just want non-zero values.\n",
    "\n",
    "For a matrix, the classic representation is a 2D array, where each row of the matrix is saves as an array, and the space is proportional to $N^2$. Instead, you can use a sparse matrix representation where each row of the matrix is a sparse vector. You have efficient access to the elements and the space is proportional to the number of non-zero entries (plus $N$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search Tree Summary\n",
    "\n",
    "The worst case (WC) is after $N$ inserts, and the average case (AC) is after $N$ random inserts.\n",
    "\n",
    "The height of any red-black BST on $n$ keys (regardless of the order of insertion) is guaranteed to be between $\\log⁡_{2} n$ and $2 \\log_{⁡2}n$.\n",
    "\n",
    "| Implementation | WC Search | WC Insert | WC Delete | AC Search | AC Insert | AC Delete | Ordered Iteration? |\n",
    "| --- | --- | --- | --- | --- | --- | --- | --- |\n",
    "| Sequential Search (unordered list) | $N$ | $N$ | $N$ | $N/2$ | $N$ | $N/2$ | No |\n",
    "| Binary Search (ordered array) | $\\lg N$ | $N$ | $N$ | $\\lg N$ | $N/2$ | $N/2$ | Yes |\n",
    "| Binary Search Tree (BST) | $N$ | $N$ | $N$ | $1.39 \\lg N$ | $1.39 \\lg N$ | ? | Yes |\n",
    "| 2-3 Tree | $c \\lg N$ | $c \\lg N$ | $c \\lg N$ | $c \\lg N$ | $c \\lg N$ | $c \\lg N$ | Yes |\n",
    "| Red-Black BST | $2 \\lg N$ | $2 \\lg N$ | $2 \\lg N$ | $1.00 \\lg N$\\* | $1.00 \\lg N$\\* | $1.00 \\lg N$ | Yes |\n",
    "| Hash: Separate Chaining | $\\lg N$\\*\\* | $\\lg N$\\*\\* | $\\lg N$\\*\\* | $3 \\cdot 5$\\*\\* | $3 \\cdot 5$\\*\\* | $3 \\cdot 5$\\*\\* | No |\n",
    "| Hash: Linear Probing | $\\lg N$\\*\\* | $\\lg N$\\*\\* | $\\lg N$\\*\\* | $3 \\cdot 5$\\*\\* | $3 \\cdot 5$\\*\\* | $3 \\cdot 5$\\*\\* | No |\n",
    "\n",
    "\\* Exact coefficient unknown but extremely close to 1  \n",
    "\\*\\* Under uniform hashing assumption"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
